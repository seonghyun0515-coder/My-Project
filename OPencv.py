import cv2
import numpy as np
import easyocr
import re
import pandas as pd
from datetime import datetime
import os

# GPUê°€ ì—†ìœ¼ë©´ CPU ëª¨ë“œë¡œ ì‹¤í–‰
print("EasyOCR ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì ì‹œ ëŒ€ê¸°)")
reader = easyocr.Reader(['ko', 'en'], gpu=False)
print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ì¹´ë©”ë¼ë¥¼ ì¼­ë‹ˆë‹¤...")

def open_cam(index=0):
    # ìœˆë„ìš° ìµœì í™” (CAP_DSHOW)
    cap = cv2.VideoCapture(index, cv2.CAP_DSHOW)
    if not cap.isOpened():
        cap.release()
        cap = cv2.VideoCapture(index, cv2.CAP_ANY)
    
    if not cap.isOpened():
        raise RuntimeError("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # [ìˆ˜ì • 1] í•´ìƒë„ FHD(1920x1080)ë¡œ ìƒí–¥ -> ê¸€ìê°€ í›¨ì”¬ ì„ ëª…í•´ì§
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
    
    # ì‹¤ì œ ì ìš©ëœ í•´ìƒë„ í™•ì¸
    w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
    h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
    print(f"ì¹´ë©”ë¼ í•´ìƒë„ ì„¤ì •: {int(w)}x{int(h)}")
    
    return cap

def order_points(pts):
    # ì‚¬ê°í˜•ì˜ 4ê°œ ì  ìˆœì„œë¥¼ (ì¢Œìƒ, ìš°ìƒ, ìš°í•˜, ì¢Œí•˜)ë¡œ ì •ë ¬
    pts = np.array(pts, dtype="float32")
    s = pts.sum(axis=1)
    diff = np.diff(pts, axis=1)
    rect = np.zeros((4,2), dtype="float32")
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect

def four_point_transform(image, pts):
    # ì°Œê·¸ëŸ¬ì§„ ì‚¬ê°í˜•ì„ ë°˜ë“¯í•œ ì§ì‚¬ê°í˜•ìœ¼ë¡œ í´ì£¼ëŠ” í•¨ìˆ˜
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    widthA = np.linalg_norm(br - bl)
    widthB = np.linalg_norm(tr - tl)
    heightA = np.linalg_norm(tr - br)
    heightB = np.linalg_norm(tl - bl)
    maxW = int(max(widthA, widthB))
    maxH = int(max(heightA, heightB))
    dst = np.array([[0, 0], [maxW - 1, 0], [maxW - 1, maxH - 1], [0, maxH - 1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    return cv2.warpPerspective(image, M, (maxW, maxH))

def find_receipt_contour(image):
    # ì˜ìˆ˜ì¦ ì™¸ê³½ì„ (ì‚¬ê°í˜•) ì°¾ê¸°
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(gray, 75, 200)
    
    contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]
    
    for c in contours:
        peri = cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, 0.02 * peri, True)
        # ì ì´ 4ê°œì´ê³ (ì‚¬ê°í˜•), í¬ê¸°ê°€ ì¼ì • ì´ìƒì¼ ë•Œë§Œ ì˜ìˆ˜ì¦ìœ¼ë¡œ ì¸ì •
        if len(approx) == 4 and cv2.contourArea(approx) > 1000:
            return approx.reshape(4, 2), edges
    return None, edges

def to_scanned(img):
    # [ìˆ˜ì • 2] ì´ì§„í™”(í‘ë°±) ëŒ€ì‹  'íšŒìƒ‰ì¡° + ì„ ëª…í•˜ê²Œ' ì²˜ë¦¬
    # EasyOCRì€ ì•„ì˜ˆ í‘ë°±(Binary)ë³´ë‹¤ íšŒìƒ‰(Grayscale)ì—ì„œ ë” ì˜ ì½ì„ ë•Œê°€ ë§ìŠµë‹ˆë‹¤.
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # CLAHE: ëŒ€ë¹„(Contrast)ë¥¼ ì œí•œì ìœ¼ë¡œ ë†’ì—¬ì„œ ê¸€ìë¥¼ ì§„í•˜ê²Œ ë§Œë“¦
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    
    return enhanced

def parse_receipt_text(text: str):
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    joined = " ".join(lines)
    
    # 1. ê¸ˆì•¡ ì¶”ì¶œ (ìˆ«ìì™€ ì½¤ë§ˆ)
    total_price = "0"
    # 'í•©ê³„', 'ì´ì•¡' ë’¤ì— ì˜¤ëŠ” ìˆ«ì ìš°ì„  ê²€ìƒ‰
    price_pattern = r'(í•©ê³„|ì´ì•¡|ê²°ì œê¸ˆì•¡|ê¸ˆì•¡|Total)[^0-9]*([\d,]+)'
    match = re.search(price_pattern, joined)
    if match:
        total_price = match.group(2).replace(',', '')
    else:
        # ëª» ì°¾ìœ¼ë©´ 'ì›' ì ì•ì— ìˆëŠ” ìˆ«ì ì¤‘ ê°€ì¥ í° ê²ƒì„ ê¸ˆì•¡ìœ¼ë¡œ ì¶”ì •
        possible_prices = re.findall(r'([\d,]+)\s*ì›', joined)
        nums = []
        for p in possible_prices:
            clean_p = p.replace(',', '')
            if clean_p.isdigit():
                nums.append(int(clean_p))
        if nums:
            total_price = str(max(nums))

    # 2. ë‚ ì§œ ì¶”ì¶œ (YYYY-MM-DD ë˜ëŠ” YYYY.MM.DD)
    date = "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
    date_match = re.search(r'(\d{4}[-./]\d{1,2}[-./]\d{1,2})', joined)
    if date_match: 
        date = date_match.group(1)

    # 3. ìƒí˜¸ëª… (ê°„ë‹¨íˆ ì²« ë²ˆì§¸ ì¤„ì„ ìƒí˜¸ë¡œ ê°€ì •í•˜ê±°ë‚˜, 'ì 'ìœ¼ë¡œ ëë‚˜ëŠ” ë‹¨ì–´ ì°¾ê¸°)
    store = "ìƒí˜¸ ë¯¸ìƒ"
    if lines:
        store = lines[0] # ë³´í†µ ì²« ì¤„ì´ ê°€ê²Œ ì´ë¦„
        
    return {"store": store, "date": date, "total_amount": total_price}

def ocr_and_export(img, excel_path="receipts.xlsx"):
    print("\n[OCR] ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘... (í™”ë©´ì´ ì ì‹œ ë©ˆì¶¥ë‹ˆë‹¤)")
    
    # OCR ì‹¤í–‰
    result = reader.readtext(img, detail=0)
    full_text = "\n".join(result)
    print(f"\n--- [ì½ì€ ë‚´ìš©] ---\n{full_text}\n---------------------")
    
    # íŒŒì‹± ë° ì €ì¥
    parsed = parse_receipt_text(full_text)
    parsed['timestamp'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    try:
        if os.path.exists(excel_path):
            df = pd.read_excel(excel_path)
            df = pd.concat([df, pd.DataFrame([parsed])], ignore_index=True)
        else:
            df = pd.DataFrame([parsed])
        
        df.to_excel(excel_path, index=False)
        print(f"âœ… ì—‘ì…€ ì €ì¥ ì„±ê³µ! -> {parsed}")
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨ (íŒŒì¼ì„ ë‹«ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”): {e}")

def main():
    cap = open_cam(0)
    print("\n=== [ì‚¬ìš©ë²•] ===")
    print("1. ì˜ìˆ˜ì¦ì„ ì–´ë‘ìš´ ë°°ê²½ ìœ„ì— ë†“ìœ¼ì„¸ìš”.")
    print("2. ì¹´ë©”ë¼ë¥¼ ì›€ì§ì—¬ ì´ˆë¡ìƒ‰ ë„¤ëª¨ê°€ ì˜ìˆ˜ì¦ì„ ê°ì‹¸ê²Œ í•˜ì„¸ìš”.")
    print("3. 's' í‚¤: ìŠ¤ìº”(í´ê¸°) ë¯¸ë¦¬ë³´ê¸° (ê¸€ìê°€ ì„ ëª…í•œì§€ í™•ì¸!)")
    print("4. 'o' í‚¤: OCR ì¸ì‹ ë° ì—‘ì…€ ì €ì¥")
    print("5. 'q' í‚¤: ì¢…ë£Œ")
    
    last_scanned = None
    
    while True:
        ret, frame = cap.read()
        if not ret: break
        
        disp = frame.copy()
        quad, edges = find_receipt_contour(frame)
        
        # ì¸ì‹ëœ ì˜ì—­ ê·¸ë¦¬ê¸°
        if quad is not None:
            cv2.polylines(disp, [quad.astype(int)], True, (0, 255, 0), 3)
            
        cv2.imshow("Camera", disp)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'): 
            break
        elif key == ord('s'):
            if quad is None:
                print("âš ï¸ ì˜ìˆ˜ì¦ ìœ¤ê³½ì„ ì„ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤. ë°°ê²½ì„ ë” ì–´ë‘¡ê²Œ í•´ë³´ì„¸ìš”.")
            else:
                # íˆ¬ì‹œ ë³€í™˜ ë° ì „ì²˜ë¦¬
                warped = four_point_transform(frame, quad)
                last_scanned = to_scanned(warped)
                cv2.imshow("Scanned Preview", last_scanned)
                print("ğŸ“¸ ìŠ¤ìº” ì™„ë£Œ! ë¯¸ë¦¬ë³´ê¸° ì°½ì˜ ê¸€ìê°€ ì„ ëª…í•œê°€ìš”? ê·¸ë ‡ë‹¤ë©´ 'o'ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
                
        elif key == ord('o'):
            if last_scanned is not None:
                ocr_and_export(last_scanned)
            else:
                print("âš ï¸ ë¨¼ì € 's'ë¥¼ ëˆŒëŸ¬ ìŠ¤ìº”ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
                
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
